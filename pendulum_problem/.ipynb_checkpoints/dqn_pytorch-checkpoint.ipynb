{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0').unwrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda:02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    print(durations_t.numpy().shape)\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "#     if is_ipython:\n",
    "#         display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 1\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
